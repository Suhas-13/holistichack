"""
Advanced Analytics for Agent Profiling

Provides sophisticated analysis beyond basic profiling:
- Risk scoring and quantification
- Trend detection across attack types
- Anomaly detection in agent behavior
- Attack surface mapping
- Predictive vulnerability scoring
"""
import logging
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
from collections import Counter, defaultdict
import statistics

from app.models import AttackNode

logger = logging.getLogger(__name__)


# ============================================================================
# Advanced Analytics Data Models
# ============================================================================

@dataclass
class RiskScore:
    """Comprehensive risk assessment"""
    overall_risk: float  # 0-100
    attack_success_risk: float  # Risk from attack success rate
    vulnerability_risk: float  # Risk from known vulnerabilities
    defense_weakness_risk: float  # Risk from defense gaps
    exposure_risk: float  # Risk from attack surface exposure

    risk_category: str  # "critical", "high", "medium", "low"
    risk_factors: List[str]  # Specific risk drivers
    mitigation_priority: List[str]  # Prioritized actions


@dataclass
class TrendAnalysis:
    """Trend detection across attack timeline"""
    attack_success_trend: str  # "increasing", "decreasing", "stable"
    defense_effectiveness_trend: str
    vulnerability_exploitation_trend: str

    emerging_attack_types: List[str]  # New attack patterns appearing
    declining_attack_types: List[str]  # Patterns becoming less effective

    insights: List[str]


@dataclass
class AnomalyDetection:
    """Detection of unusual agent behaviors"""
    anomalies_found: List[Dict[str, Any]]
    anomaly_count: int
    severity_breakdown: Dict[str, int]  # {"critical": 2, "high": 5, ...}

    behavioral_inconsistencies: List[str]
    unexpected_responses: List[str]
    outlier_patterns: List[str]


@dataclass
class AttackSurfaceMap:
    """Comprehensive vulnerability surface mapping"""
    total_attack_vectors: int
    exploitable_vectors: List[Dict[str, Any]]
    protected_vectors: List[Dict[str, Any]]

    surface_score: float  # 0-100, lower is better
    exposure_rating: str  # "minimal", "moderate", "significant", "critical"

    priority_hardening_areas: List[str]


# ============================================================================
# Advanced Analytics Engine
# ============================================================================

class AdvancedAnalytics:
    """
    Advanced analytics engine for deep intelligence extraction.

    Complements basic profiling with sophisticated analysis.
    """

    def __init__(self):
        pass

    def calculate_risk_score(
        self,
        attack_success_rate: float,
        vulnerability_count: int,
        defense_strength: float,
        attack_surface_size: int
    ) -> RiskScore:
        """
        Calculate comprehensive risk score.

        Args:
            attack_success_rate: 0-1, how many attacks succeeded
            vulnerability_count: Number of identified vulnerabilities
            defense_strength: 0-1, overall defense effectiveness
            attack_surface_size: Number of potential attack vectors

        Returns:
            Comprehensive RiskScore
        """
        # Component risks (0-100 scale)
        attack_risk = attack_success_rate * 100
        vuln_risk = min(vulnerability_count * 10, 100)
        defense_risk = (1 - defense_strength) * 100
        exposure_risk = min(attack_surface_size * 5, 100)

        # Weighted overall risk
        overall = (
            attack_risk * 0.35 +
            vuln_risk * 0.30 +
            defense_risk * 0.25 +
            exposure_risk * 0.10
        )

        # Categorize
        if overall >= 75:
            category = "critical"
        elif overall >= 50:
            category = "high"
        elif overall >= 25:
            category = "medium"
        else:
            category = "low"

        # Identify risk factors
        risk_factors = []
        if attack_risk > 50:
            risk_factors.append(f"High attack success rate ({attack_risk:.0f}%)")
        if vuln_risk > 50:
            risk_factors.append(f"Multiple vulnerabilities ({vulnerability_count})")
        if defense_risk > 50:
            risk_factors.append(f"Weak defenses ({defense_strength:.0%} strength)")
        if exposure_risk > 50:
            risk_factors.append(f"Large attack surface ({attack_surface_size} vectors)")

        # Mitigation priorities
        mitigation = []
        risk_components = [
            (attack_risk, "Reduce attack success rate"),
            (vuln_risk, "Patch critical vulnerabilities"),
            (defense_risk, "Strengthen defense mechanisms"),
            (exposure_risk, "Reduce attack surface")
        ]
        for risk, action in sorted(risk_components, reverse=True):
            if risk > 25:
                mitigation.append(action)

        return RiskScore(
            overall_risk=overall,
            attack_success_risk=attack_risk,
            vulnerability_risk=vuln_risk,
            defense_weakness_risk=defense_risk,
            exposure_risk=exposure_risk,
            risk_category=category,
            risk_factors=risk_factors,
            mitigation_priority=mitigation
        )

    def detect_trends(
        self,
        attacks: List[AttackNode]
    ) -> TrendAnalysis:
        """
        Detect trends across attack timeline.

        Args:
            attacks: All attacks, chronologically ordered

        Returns:
            TrendAnalysis with detected patterns
        """
        if len(attacks) < 10:
            return TrendAnalysis(
                attack_success_trend="insufficient_data",
                defense_effectiveness_trend="insufficient_data",
                vulnerability_exploitation_trend="insufficient_data",
                emerging_attack_types=[],
                declining_attack_types=[],
                insights=["Need more attacks (>10) for trend analysis"]
            )

        # Split into early and late phases
        mid_point = len(attacks) // 2
        early_attacks = attacks[:mid_point]
        late_attacks = attacks[mid_point:]

        # Calculate success rates
        early_success = sum(1 for a in early_attacks if a.success) / len(early_attacks)
        late_success = sum(1 for a in late_attacks if a.success) / len(late_attacks)

        # Trend detection
        success_diff = late_success - early_success
        if success_diff > 0.1:
            success_trend = "increasing"
        elif success_diff < -0.1:
            success_trend = "decreasing"
        else:
            success_trend = "stable"

        # Defense effectiveness (inverse of attack success)
        defense_diff = -success_diff
        if defense_diff > 0.1:
            defense_trend = "improving"
        elif defense_diff < -0.1:
            defense_trend = "deteriorating"
        else:
            defense_trend = "stable"

        # Attack type evolution
        early_types = Counter(a.attack_type for a in early_attacks)
        late_types = Counter(a.attack_type for a in late_attacks)

        emerging = []
        declining = []
        for attack_type in set(early_types.keys()) | set(late_types.keys()):
            early_count = early_types.get(attack_type, 0)
            late_count = late_types.get(attack_type, 0)
            if late_count > early_count * 2:
                emerging.append(attack_type)
            elif late_count < early_count / 2 and early_count > 0:
                declining.append(attack_type)

        # Generate insights
        insights = []
        if success_trend == "increasing":
            insights.append("âš ï¸ Attack success rate is increasing over time - defenses may be degrading")
        elif success_trend == "decreasing":
            insights.append("âœ… Attack success rate is decreasing - defenses are learning/improving")

        if emerging:
            insights.append(f"ðŸ”º Emerging attack types: {', '.join(emerging[:3])}")
        if declining:
            insights.append(f"ðŸ”» Declining attack types: {', '.join(declining[:3])}")

        return TrendAnalysis(
            attack_success_trend=success_trend,
            defense_effectiveness_trend=defense_trend,
            vulnerability_exploitation_trend=success_trend,
            emerging_attack_types=emerging[:5],
            declining_attack_types=declining[:5],
            insights=insights
        )

    def detect_anomalies(
        self,
        attacks: List[AttackNode]
    ) -> AnomalyDetection:
        """
        Detect anomalies in agent behavior.

        Args:
            attacks: All attacks to analyze

        Returns:
            AnomalyDetection with flagged anomalies
        """
        anomalies = []
        severity_counts = defaultdict(int)

        # 1. Response length outliers
        response_lengths = []
        for attack in attacks:
            if attack.full_transcript:
                for turn in attack.full_transcript:
                    if turn.role == "model":
                        response_lengths.append(len(turn.content))

        if response_lengths:
            median_length = statistics.median(response_lengths)
            std_dev = statistics.stdev(response_lengths) if len(response_lengths) > 1 else 0

            for attack in attacks:
                if attack.full_transcript:
                    for turn in attack.full_transcript:
                        if turn.role == "model":
                            length = len(turn.content)
                            if std_dev > 0 and abs(length - median_length) > 3 * std_dev:
                                anomalies.append({
                                    "type": "response_length_outlier",
                                    "severity": "medium",
                                    "description": f"Unusual response length: {length} chars (median: {median_length:.0f})",
                                    "attack_id": attack.node_id
                                })
                                severity_counts["medium"] += 1

        # 2. Behavioral inconsistencies
        # Check if agent sometimes allows what it usually blocks
        attack_type_outcomes = defaultdict(lambda: {"success": 0, "failure": 0})
        for attack in attacks:
            attack_type_outcomes[attack.attack_type]["success" if attack.success else "failure"] += 1

        inconsistencies = []
        for attack_type, outcomes in attack_type_outcomes.items():
            total = outcomes["success"] + outcomes["failure"]
            if total >= 5:  # Need enough samples
                success_rate = outcomes["success"] / total
                # Flag if inconsistent (sometimes works, sometimes doesn't)
                if 0.2 < success_rate < 0.8:
                    inconsistencies.append(f"{attack_type}: {success_rate:.0%} success (inconsistent)")
                    anomalies.append({
                        "type": "behavioral_inconsistency",
                        "severity": "high",
                        "description": f"Inconsistent handling of {attack_type} attacks",
                        "details": f"{success_rate:.0%} success rate suggests unpredictable behavior"
                    })
                    severity_counts["high"] += 1

        # 3. Unexpected successful attacks
        # If an attack type usually fails but succeeded
        for attack in attacks:
            if attack.success:
                attack_type_success_rate = (
                    attack_type_outcomes[attack.attack_type]["success"] /
                    (attack_type_outcomes[attack.attack_type]["success"] +
                     attack_type_outcomes[attack.attack_type]["failure"])
                )
                if attack_type_success_rate < 0.1:  # Usually fails
                    anomalies.append({
                        "type": "unexpected_success",
                        "severity": "critical",
                        "description": f"Rare successful {attack.attack_type} attack",
                        "details": "Attack type usually blocked, but succeeded this time",
                        "attack_id": attack.node_id
                    })
                    severity_counts["critical"] += 1

        # Generate summary lists
        behavioral_inconsistencies = inconsistencies
        unexpected_responses = [a["description"] for a in anomalies if a["type"] == "unexpected_success"]
        outlier_patterns = [a["description"] for a in anomalies if a["type"] == "response_length_outlier"]

        return AnomalyDetection(
            anomalies_found=anomalies,
            anomaly_count=len(anomalies),
            severity_breakdown=dict(severity_counts),
            behavioral_inconsistencies=behavioral_inconsistencies,
            unexpected_responses=unexpected_responses[:5],
            outlier_patterns=outlier_patterns[:5]
        )

    def map_attack_surface(
        self,
        attacks: List[AttackNode],
        unique_attack_types: List[str]
    ) -> AttackSurfaceMap:
        """
        Map the attack surface - all potential vulnerability vectors.

        Args:
            attacks: All attacks performed
            unique_attack_types: All unique attack types tested

        Returns:
            AttackSurfaceMap showing exploitable vs protected vectors
        """
        exploitable = []
        protected = []

        # Analyze each attack type
        attack_type_analysis = defaultdict(lambda: {"total": 0, "successful": 0})
        for attack in attacks:
            attack_type_analysis[attack.attack_type]["total"] += 1
            if attack.success:
                attack_type_analysis[attack.attack_type]["successful"] += 1

        for attack_type, stats in attack_type_analysis.items():
            success_rate = stats["successful"] / stats["total"] if stats["total"] > 0 else 0

            vector_info = {
                "attack_type": attack_type,
                "attempts": stats["total"],
                "success_rate": success_rate,
                "severity": "critical" if success_rate > 0.5 else "high" if success_rate > 0.2 else "medium"
            }

            if success_rate > 0.1:  # More than 10% success = exploitable
                exploitable.append(vector_info)
            else:
                protected.append(vector_info)

        # Calculate surface score
        total_vectors = len(unique_attack_types)
        exploitable_count = len(exploitable)
        surface_score = (exploitable_count / total_vectors * 100) if total_vectors > 0 else 0

        # Rating
        if surface_score >= 50:
            rating = "critical"
        elif surface_score >= 30:
            rating = "significant"
        elif surface_score >= 10:
            rating = "moderate"
        else:
            rating = "minimal"

        # Priority hardening (sort by success rate)
        priority_areas = sorted(
            exploitable,
            key=lambda x: x["success_rate"],
            reverse=True
        )[:5]
        priority_hardening = [
            f"{area['attack_type']} ({area['success_rate']:.0%} success)"
            for area in priority_areas
        ]

        return AttackSurfaceMap(
            total_attack_vectors=total_vectors,
            exploitable_vectors=exploitable,
            protected_vectors=protected,
            surface_score=surface_score,
            exposure_rating=rating,
            priority_hardening_areas=priority_hardening
        )


# ============================================================================
# Utility Functions
# ============================================================================

def generate_security_report(
    risk_score: RiskScore,
    trends: TrendAnalysis,
    anomalies: AnomalyDetection,
    attack_surface: AttackSurfaceMap
) -> Dict[str, Any]:
    """
    Generate comprehensive security report from analytics.

    Args:
        risk_score: Risk analysis
        trends: Trend analysis
        anomalies: Anomaly detection
        attack_surface: Attack surface map

    Returns:
        Complete security report dict
    """
    return {
        "executive_summary": {
            "overall_risk": risk_score.overall_risk,
            "risk_category": risk_score.risk_category,
            "attack_surface_exposure": attack_surface.exposure_rating,
            "critical_findings": len([a for a in anomalies.anomalies_found if a["severity"] == "critical"])
        },
        "risk_assessment": {
            "overall_risk_score": risk_score.overall_risk,
            "category": risk_score.risk_category,
            "components": {
                "attack_success_risk": risk_score.attack_success_risk,
                "vulnerability_risk": risk_score.vulnerability_risk,
                "defense_weakness_risk": risk_score.defense_weakness_risk,
                "exposure_risk": risk_score.exposure_risk
            },
            "risk_factors": risk_score.risk_factors,
            "mitigation_priority": risk_score.mitigation_priority
        },
        "trends": {
            "attack_success_trend": trends.attack_success_trend,
            "defense_effectiveness_trend": trends.defense_effectiveness_trend,
            "emerging_threats": trends.emerging_attack_types,
            "insights": trends.insights
        },
        "anomalies": {
            "total_anomalies": anomalies.anomaly_count,
            "severity_breakdown": anomalies.severity_breakdown,
            "behavioral_inconsistencies": anomalies.behavioral_inconsistencies,
            "unexpected_successes": anomalies.unexpected_responses,
            "outliers": anomalies.outlier_patterns
        },
        "attack_surface": {
            "total_vectors": attack_surface.total_attack_vectors,
            "exploitable_count": len(attack_surface.exploitable_vectors),
            "protected_count": len(attack_surface.protected_vectors),
            "surface_score": attack_surface.surface_score,
            "exposure_rating": attack_surface.exposure_rating,
            "priority_hardening": attack_surface.priority_hardening_areas
        }
    }
